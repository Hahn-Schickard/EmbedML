{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellkomprimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook ist Teil des Projekts [EmbedML](https://hahn-schickard.gitbook.io/embedml) und basiert auf den Inhalten des Kapitels [Modellkomprimierung](https://hahn-schickard.gitbook.io/embedml/3_tinyml/3.3_modellkomprimierung). Es ist auf [Colab]() und im [GitHub-Repository von Hahn-Schickard]() zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation der benötigten Bibliotheken in den angegebenen Versionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Das System kann den angegebenen Pfad nicht finden.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q numpy==1.26.4 scikit-learn==1.5.2 tensorflow-gpu==2.10 tensorflow-model-optimization==0.8.0 > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es werden Ordner erstellt, falls diese noch nicht vohanden sind, in welchen die in diesem Notebook erstellten Modelle gespeichert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('assets')):\n",
    "    os.makedirs(os.path.join('assets'))\n",
    "    \n",
    "if not os.path.exists(os.path.join('assets', 'models')):\n",
    "    os.makedirs(os.path.join('assets', 'models'))\n",
    "    \n",
    "if not os.path.exists(os.path.join('assets', 'models', 'tf')):\n",
    "    os.makedirs(os.path.join('assets', 'models', 'tf'))\n",
    "    \n",
    "if not os.path.exists(os.path.join('assets', 'models', 'tflite')):\n",
    "    os.makedirs(os.path.join('assets', 'models', 'tflite'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Basline Modell wird trainiert, welches als Grundlage für das Notebook dient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im ersten Schritt, wird der MNIST-Datensatz geladen. Die Pixelwerte des MNIST-Datensatzes werden durch 255 geteilt, um sie auf den Bereich von 0 bis 1 zu normalisieren, da die ursprünglichen Werte zwischen 0 und 255 liegen. Im selben Schritt werden die Daten, in den Datentyp float32 konvertiert und in Trainings- und Testdaten aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train / 255.0).astype(np.float32)\n",
    "X_test = (X_test / 255.0).astype(np.float32)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die Verwendung von np.expand_dims mit axis=3 wird eine neue Dimension an der vierten Position (Index 3) der Arrays `X_train` und `X_test` hinzugefügt. Durch das Hinzufügen einer zusätzlichen Dimension wird die Form zu (Anzahl_Bilder, Höhe, Breite, Kanäle), was später für das neuronale Netz erforderlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `create_model` definiert ein sequentielles neuronales Netzwerk in TensorFlow, das für die Klassifikation von Bildern mit einer Eingabegröße von 28x28x1 Pixeln konzipiert ist. Das Modell beginnt mit einer 2D-Faltungsschicht (Conv2D), um Merkmale aus den Eingabedaten zu extrahieren, gefolgt von einer Max-Pooling-Schicht (MaxPooling2D), die die räumlichen Dimensionen der Daten reduziert. Diese Schichten folgen erneut. Die resultierenden Merkmalskarten werden durch eine Flatten-Schicht in einen eindimensionalen Vektor umgewandelt. Dieser Vektor wird dann durch vollvernetzte Schichten (Dense) verarbeitet, gefolgt von Dropout-Schichten (Dropout) zur Vermeidung von Überanpassung. Abschließend liefert eine Dense-Ausgabeschicht mit 10 Neuronen und der Softmax-Aktivierungsfunktion die Wahrscheinlichkeiten für jede der 10 Klassen. Das Modell wird mit dem Adam-Optimizer trainiert und verwendet die Verlustfunktion sparse_categorical_crossentropy. Als Metrik zur Bewertung der Modellleistung wird die Genauigkeit (accuracy) herangezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Definition eines neuronalen Netzes\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das zuvor definierte Modell mit den Trainingsdaten `X_train` und den zugehörigen Label `y_train`, beispielhaft für 5 Epochen trainiert, wobei 20% der Daten für die Validierung verwendet werden, um die Leistung des Modells während des Trainings zu überwachen und Überanpassung zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                12832     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,010\n",
      "Trainable params: 16,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 14s 8ms/step - loss: 0.9516 - accuracy: 0.6799 - val_loss: 0.1932 - val_accuracy: 0.9477\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.3575 - accuracy: 0.8889 - val_loss: 0.1224 - val_accuracy: 0.9658\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2670 - accuracy: 0.9201 - val_loss: 0.1017 - val_accuracy: 0.9718\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2221 - accuracy: 0.9361 - val_loss: 0.0919 - val_accuracy: 0.9749\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1984 - accuracy: 0.9419 - val_loss: 0.0784 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba8009ff10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ursprüngliche Modell wird mit den Testdaten evaluiert, um die Testgenauigkeit zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Baseline Test Accuracy: {baseline_model_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte TensorFlow Modell wird in die Datei `mnist_model.h5` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('assets', 'models', 'tf', 'mnist_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt werden drei Quantisierungstechniken vorgestellt:\n",
    "- Statische Quantisierung (Post-training quantization, PTQ)\n",
    "- Dynamische Quantisierung\n",
    "- Quantisierungs-bewusstes Training (Quantization-Aware Training, QAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statische Quantisierung (Post-training quantization, PTQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das zuvor trainierte Baseline Modell wird geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(os.path.join('assets', 'models', 'tf', 'mnist_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `representative_dataset_gen` dient dazu, eine repräsentative Stichprobe des Trainingsdatensatzes für die Kalibrierung eines TensorFlow Lite Modells bereitzustellen. Sie iteriert hier über die ersten 500 Datenpunkte des Trainingsdatensatzes `X_train` und gibt jedes Beispiel als Liste mit einem Element zurück. Dies ist erforderlich, da das Modell nur einen Eingabewert erwartet, und die Kalibrierungsfunktion eine Liste von Eingabewerten benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen(dataset):\n",
    "    # Erstellen eines tf.data.Dataset und Batch-Größe von 1\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset).batch(1)\n",
    "    # Iteriere über die ersten 500 Datenpunkte des Trainingsdatensatzes\n",
    "    for input_value in dataset.take(500):\n",
    "        # Das Modell erwartet nur einen Eingabewert, daher wird jedes Beispiel\n",
    "        # als Liste mit einem einzigen Element zurückgegeben.\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Codeabschnitt konvertiert das Baseline Modell in ein TensorFlow Lite Modell und wendet die Quantisierung an:\n",
    "- Zuerst wird ein Converter-Objekt initialisiert, das das Modell lädt\n",
    "- Dann werden Optimierungen für die Konvertierung festgelegt, einschließlich der Verwendung eines repräsentativen Datensatzes (`representative_dataset_gen`) zur Bestimmung der Quantisierungsparameter. Das Modell wird auf int8-Basis quantisiert, was bedeutet, dass Eingaben und Ausgaben während der Inferenz als 8-Bit Ganzzahlen behandelt werden, was Speicherplatz spart und die Ausführungsgeschwindigkeit auf entsprechender Hardware beschleunigen kann.\n",
    "- Schließlich wird das konvertierte quantisierte Modell `tflite_model_quant` erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmpq899wu7c\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmpq899wu7c\\assets\n",
      "C:\\Users\\dk100\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Konverter-Objekt wird aus dem Baseline Modell erstellt\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Optimierungen werden auf Standardwerte gesetzt, um die Konvertierung zu optimieren\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Festlegen eines repräsentativen Datensatzes für die statische Quantisierung\n",
    "converter.representative_dataset = lambda: representative_dataset_gen(X_train)\n",
    "\n",
    "# Festlegen der unterstützten Operationen auf TensorFlow Lite eingebauten int8-Operationen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Festlegen des Eingabetyps für Inferenzen auf 8-Bit Ganzzahlen (uint8)\n",
    "converter.inference_input_type = tf.uint8\n",
    "\n",
    "# Festlegen des Ausgabetyps für Inferenzen auf 8-Bit Ganzzahlen (uint8)\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "# Konvertieren des Modells in ein TensorFlow Lite Modell mit Quantisierung\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das quantisierte TensorFlow Lite Modell wird in die Datei `mnist_model_quant.tflite` im Binärformat geschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('assets', 'models', 'tflite', 'mnist_model_quant.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das quantisierte TensorFlow Lite Modell aus der Datei `mnist_model_quant.tflite` geladen und ein Interpreter initialisiert, um die Eingabe- und Ausgabedetails des Modells abzurufen und Speicher für die Ausführung des Modells zuzuweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des TensorFlow Lite Interpreters mit dem quantisierten Modell\n",
    "interpreter = tf.lite.Interpreter(model_path=os.path.join('assets', 'models', 'tflite', 'mnist_model_quant.tflite'))\n",
    "\n",
    "# Allokieren von Speicher für den Interpreter, um das Modell auszuführen\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Abrufen der Details für die Eingabedaten des Modells\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Abrufen der Details für die Ausgabedaten des Modells\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_test_uint8` wird erstellt, indem die Werte von `X_test` auf den Bereich von 0 bis 255 skaliert und dann als 8-Bit Ganzzahlen (uint8) gespeichert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_uint8 = (X_test * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird über alle quantisierten Testdaten iteriert: Für jedes Bild wird die Eingabe in das TensorFlow Lite Modell geladen, die Inferenz ausgeführt und dann überprüft, ob die vorhergesagte Klasse mit dem tatsächlichen Label `y_test` übereinstimmt. Wenn dies der Fall ist, wird die Anzahl der korrekten Vorhersagen um 1 erhöht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung der Anzahl korrekter Vorhersagen\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iteration über alle Testdaten\n",
    "for i in range(len(X_test_uint8)):\n",
    "    # Vorbereitung der Eingabedaten für den Interpreter durch Hinzufügen einer zusätzlichen Dimension\n",
    "    input_data = np.expand_dims(X_test_uint8[i], axis=0)\n",
    "    \n",
    "    # Setzen der Eingabedaten im Interpreter\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Ausführen der Inferenz\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Abrufen der Ausgabedaten vom Interpreter\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Überprüfen, ob die vorhergesagte Klasse mit dem tatsächlichen Label übereinstimmt\n",
    "    if np.argmax(output_data) == y_test[i]:\n",
    "        correct_predictions += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit des quantisierten Modells wird berechnet, indem die Anzahl der korrekten Vorhersagen durch die Gesamtanzahl der Testdaten geteilt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ Test Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "ptq_accuracy = correct_predictions / len(X_test)\n",
    "print(f'PTQ Test Accuracy: {ptq_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamische Quantisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das zuvor trainierte Baseline Modell wird geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(os.path.join('assets', 'models', 'tf', 'mnist_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein TensorFlow Lite Converter wird initialisiert, um das Baseline Modell zu konvertieren, wobei Standardoptimierungen angewendet werden. Das konvertierte Modell `tflite_dynamic_quant_model` nutzt dynamische Quantisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp74_h5g06\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp74_h5g06\\assets\n"
     ]
    }
   ],
   "source": [
    "# Initialisierung des TensorFlow Lite Converters mit dem Baseline Modell\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Festlegen von Standardoptimierungen für die Konvertierung\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Konvertieren des Modells unter Verwendung von dynamischer Quantisierung\n",
    "tflite_dynamic_quant_model = converter.convert() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das TensorFlow Lite Modell mit dynamischer Quantisierung wird in die Datei `mnist_dynamic_quant_model.tflite` im Binärformat geschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('assets', 'models', 'tflite', 'mnist_dynamic_quant_model.tflite'), 'wb') as f:\n",
    "    f.write(tflite_dynamic_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisierung des TensorFlow Lite Interpreter-Objekts, um das dynamisch quantisierte Modell aus der Datei `mnist_dynamic_quant_model.tflite` zu laden. Der Speicher für die Ausführung des Modells wird zugewiesen und die Details für die Eingabe- und Ausgabedaten werden abgerufen, um die Inferenz durchführen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des TensorFlow Lite Interpreters mit dem dynamisch quantisierten Modell\n",
    "interpreter = tf.lite.Interpreter(model_path=os.path.join('assets', 'models', 'tflite', 'mnist_dynamic_quant_model.tflite'))\n",
    "\n",
    "# Allokieren von Speicher für den Interpreter, um das Modell auszuführen\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Abrufen der Details für die Eingabedaten des Modells\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Abrufen der Details für die Ausgabedaten des Modells\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird eine Schleife über alle Testdatensätze `X_test` durchgeführt: Für jedes Bild wird die Eingabe vorbereitet, indem sie um eine Dimension erweitert und in den TensorFlow Lite Interpreter gesetzt wird. Anschließend wird die Inferenz durchgeführt, die Ausgabe abgerufen und überprüft, ob die vorhergesagte Klasse mit dem tatsächlichen Label `y_test` übereinstimmt. . Wenn dies der Fall ist, wird die Anzahl der korrekten Vorhersagen um 1 erhöht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung der Zählvariable für korrekte Vorhersagen\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iteration über alle Testdaten\n",
    "for i in range(len(X_test)):\n",
    "    # Vorbereitung der Eingabedaten für den Interpreter durch Hinzufügen einer zusätzlichen Dimension und Umwandlung in float32\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    \n",
    "    # Setzen der Eingabedaten im Interpreter\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Ausführen der Inferenz\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Abrufen der Ausgabedaten vom Interpreter\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Überprüfen, ob die vorhergesagte Klasse mit dem tatsächlichen Label übereinstimmt und Zählen der korrekten Vorhersagen\n",
    "    if np.argmax(output_data) == y_test[i]:\n",
    "        correct_predictions += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit des dynamisch quantisierten Modells wird berechnet, indem die Anzahl der korrekten Vorhersagen durch die Gesamtanzahl der Testdaten geteilt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Quantization Test Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "dynamic_quant_accuracy = correct_predictions / len(X_test)\n",
    "print(f'Dynamic Quantization Test Accuracy: {dynamic_quant_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantisierungs-bewusstes Training (Quantization-Aware Training, QAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In diesem Codeabschnitt wird das Quantization-Aware Training (QAT) durchgeführt, indem ein quantisiertes Modell erstellt wird, das die Auswirkungen der Quantisierung bereits während des Trainings berücksichtigt. Das Modell wird mit einem optimierten Optimierer und Verlustfunktion trainiert, um sicherzustellen, dass es sowohl die Quantisierungsanforderungen als auch die Leistungsmetriken erfüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 6s 14ms/step - loss: 0.9257 - accuracy: 0.6914 - val_loss: 0.1840 - val_accuracy: 0.9524\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3374 - accuracy: 0.8997 - val_loss: 0.1054 - val_accuracy: 0.9689\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2507 - accuracy: 0.9264 - val_loss: 0.0972 - val_accuracy: 0.9728\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2073 - accuracy: 0.9388 - val_loss: 0.0839 - val_accuracy: 0.9762\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1824 - accuracy: 0.9461 - val_loss: 0.0740 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd42edc910>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import der Funktion zur Quantisierung des Modells aus TensorFlow Model Optimization (tfmot)\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# Erstellung eines quantisierten Modells durch Anwendung der Quantisierung auf das Baseline Modell\n",
    "q_aware_model = quantize_model(create_model())\n",
    "\n",
    "# Kompilierung des quantisierten Modells\n",
    "q_aware_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training des quantisierten Modells\n",
    "q_aware_model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte Modell wird mit den Testdaten evaluiert, um die Testgenauigkeit zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization Aware Training Model Test Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "_, q_aware_model_accuracy = q_aware_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Quantization Aware Training Model Test Accuracy: {q_aware_model_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte (QAT) Modell wird in die Datei `mnist_qat_model.h5` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model.save(os.path.join('assets', 'models', 'tf', 'mnist_qat_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hier wird das quantisierungsbewusste (QAT) Modell in ein TensorFlow Lite (TFLite) Modell konvertiert, wobei Standardoptimierungen für die Konvertierung aktiviert werden, um die Leistung und Effizienz des Modells zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_3_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp4a2nga2d\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp4a2nga2d\\assets\n",
      "C:\\Users\\dk100\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Initialisierung des TensorFlow Lite Converters mit dem quantisierungsbewussten Modell\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "\n",
    "# Festlegen von Standardoptimierungen für die Konvertierung, einschließlich der Optimierung der Quantisierung\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Konvertierung des quantisierungsbewussten Modells in ein TensorFlow Lite Modell\n",
    "tflite_qat_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das konvertierte Modell wird in das TensorFlow Lite Format in die Datei `mnist_qat_model_quant.h5` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des QAT quantisierten Modells\n",
    "with open(os.path.join('assets', 'models', 'tflite', 'mnist_qat_model_quant.tflite'), 'wb') as f:\n",
    "    f.write(tflite_qat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisierung des TensorFlow Lite Interpreter-Objekts, um das quantisierungsbewusste Modell aus der Datei `mnist_qat_model_quant.tflite` zu laden. Der Speicher für die Ausführung des Modells wird zugewiesen und die Details für die Eingabe- und Ausgabedaten werden abgerufen, um die Inferenz durchführen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des TensorFlow Lite Interpreters mit dem dynamisch quantisierten Modell\n",
    "interpreter = tf.lite.Interpreter(model_path=os.path.join('assets', 'models', 'tflite', 'mnist_qat_model_quant.tflite'))\n",
    "\n",
    "# Allokieren von Speicher für den Interpreter, um das Modell auszuführen\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Abrufen der Details für die Eingabedaten des Modells\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Abrufen der Details für die Ausgabedaten des Modells\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird eine Schleife über alle Testdatensätze `X_test` durchgeführt: Für jedes Bild wird die Eingabe vorbereitet, indem sie um eine Dimension erweitert und in den TensorFlow Lite Interpreter gesetzt wird. Anschließend wird die Inferenz durchgeführt, die Ausgabe abgerufen und überprüft, ob die vorhergesagte Klasse mit dem tatsächlichen Label `y_test` übereinstimmt. . Wenn dies der Fall ist, wird die Anzahl der korrekten Vorhersagen um 1 erhöht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung der Zählvariable für korrekte Vorhersagen\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iteration über alle Testdaten\n",
    "for i in range(len(X_test)):\n",
    "    # Vorbereitung der Eingabedaten für den Interpreter durch Hinzufügen einer zusätzlichen Dimension und Umwandlung in float32\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    \n",
    "    # Setzen der Eingabedaten im Interpreter\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Ausführen der Inferenz\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Abrufen der Ausgabedaten vom Interpreter\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Überprüfen, ob die vorhergesagte Klasse mit dem tatsächlichen Label übereinstimmt und Zählen der korrekten Vorhersagen\n",
    "    if np.argmax(output_data) == y_test[i]:\n",
    "        correct_predictions += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit des quantisierungsbewussten Modells wird berechnet, indem die Anzahl der korrekten Vorhersagen durch die Gesamtanzahl der Testdaten geteilt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization Aware Test Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "q_aware_accuracy_tflite = correct_predictions / len(X_test)\n",
    "print(f'Quantization Aware Test Accuracy: {q_aware_accuracy_tflite:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt werden zwei Pruningtechniken vorgestellt:\n",
    "- Gewichtspruning (engl. weight pruning)\n",
    "- Strukturiertes Pruning (engl. structured pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gewichtspruning (engl. weight pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das zuvor trainierte Baseline Modell wird geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(os.path.join('assets', 'models', 'tf', 'mnist_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Gewichtspruning werden individuelle Gewichte innerhalb eines neuronalen Netzwerks entfernt, um die Modellgröße zu reduzieren, ohne die Genauigkeit erheblich zu beeinträchtigen. Der folgende Codeabschnitt zeigt, wie man ein Modell mit Gewichtspruning optimieren kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d_  (None, 26, 26, 16)       306       \n",
      " 4 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 13, 13, 16)       1         \n",
      " ling2d_4 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 11, 11, 16)       4626      \n",
      " 5 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 5, 5, 16)         1         \n",
      " ling2d_5 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 400)              1         \n",
      " _2 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_6  (None, 32)               25634     \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 32)               1         \n",
      " _4 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_7  (None, 16)               1042      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 16)               1         \n",
      " _5 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_8  (None, 10)               332       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,945\n",
      "Trainable params: 16,010\n",
      "Non-trainable params: 15,935\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Anwendung von Pruning-Spezifikationen auf das Modell\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0, final_sparsity=0.5, begin_step=2000, end_step=10000)\n",
    "}\n",
    "\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(create_model(), **pruning_params)\n",
    "\n",
    "# Kompilierung des geprunten Modells\n",
    "pruned_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell wird mit Pruning für 5 Epochen trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/375 [..............................] - ETA: 30:37 - loss: 2.3219 - accuracy: 0.0625WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_train_batch_end` time: 0.0352s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_train_batch_end` time: 0.0352s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 9s 11ms/step - loss: 0.8888 - accuracy: 0.7070 - val_loss: 0.1788 - val_accuracy: 0.9533\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3607 - accuracy: 0.8910 - val_loss: 0.1195 - val_accuracy: 0.9663\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2845 - accuracy: 0.9159 - val_loss: 0.1004 - val_accuracy: 0.9703\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2386 - accuracy: 0.9291 - val_loss: 0.0895 - val_accuracy: 0.9756\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2028 - accuracy: 0.9406 - val_loss: 0.0825 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bc80806da0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callback für Pruning-Updates während des Trainings\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "\n",
    "pruned_model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das geprunte Modell wird mit den Testdaten evaluiert, um die Testgenauigkeit zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Test Accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "_, pruned_model_accuracy = pruned_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Pruned Test Accuracy: {pruned_model_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte Modell (Gewichtspruning) wird in die Datei `mnist_weight_pruning_model.h5` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.save(os.path.join('assets', 'models', 'tf', 'mnist_weight_pruning_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das geprunte Modell wird in ein TensorFlow Lite Modell konvertiert, um die Modellgröße weiter zu reduzieren und die Effizienz zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_4_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_5_layer_call_fn, conv2d_5_layer_call_and_return_conditional_losses while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp84kg3_5y\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp84kg3_5y\\assets\n"
     ]
    }
   ],
   "source": [
    "# Konvertieren des geprunten Modells in ein TensorFlow Lite Modell\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "tflite_model_pruned = converter.convert()\n",
    "\n",
    "# Speichern des verkleinerten Modells\n",
    "with open(os.path.join('assets', 'models', 'tflite', 'mnist_weight_pruning_model.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das TensorFlow Lite Modell `mnist_pruned_model.tflite` geladen und ein Interpreter initialisiert, um die Eingabe- und Ausgabedetails des Modells abzurufen und Speicher für die Ausführung des Modells zuzuweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des TensorFlow Lite Interpreters mit dem geprunten Modell\n",
    "interpreter = tf.lite.Interpreter(model_path=os.path.join('assets', 'models', 'tflite', 'mnist_weight_pruning_model.tflite'))\n",
    "\n",
    "# Allokieren von Speicher für den Interpreter, um das Modell auszuführen\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Abrufen der Details für die Eingabedaten des Modells\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Abrufen der Details für die Ausgabedaten des Modells\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird eine Schleife über alle Testdaten `X_test` durchgeführt: Für jedes Bild wird die Eingabe vorbereitet, indem sie um eine Dimension erweitert und in den TensorFlow Lite Interpreter gesetzt wird. Anschließend wird die Inferenz durchgeführt, die Ausgabe abgerufen und überprüft, ob die vorhergesagte Klasse mit dem tatsächlichen Label y_test übereinstimmt. Wenn dies der Fall ist, wird die Anzahl der korrekten Vorhersagen `correct_predictions` erhöht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung der Zählvariable für korrekte Vorhersagen\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iteration über alle Testdaten\n",
    "for i in range(len(X_test)):\n",
    "    # Vorbereitung der Eingabedaten für den Interpreter durch Hinzufügen einer\n",
    "    # zusätzlichen Dimension und Umwandlung in float32\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    \n",
    "    # Setzen der Eingabedaten im Interpreter\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Ausführen der Inferenz\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Abrufen der Ausgabedaten vom Interpreter\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Überprüfen, ob die vorhergesagte Klasse mit dem tatsächlichen Label übereinstimmt\n",
    "    if np.argmax(output_data) == y_test[i]:\n",
    "        correct_predictions += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit des geprunten Modells wird berechnet, indem die Anzahl der korrekten Vorhersagen durch die Gesamtanzahl der Testdaten geteilt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Model Test Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "pruned_model_accuracy = correct_predictions / len(X_test)\n",
    "print(f'Pruned Model Test Accuracy: {pruned_model_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning ist eine effektive Technik zur Reduzierung der Modellgröße und Verbesserung der Effizienz, insbesondere für Anwendungen auf Edge-Geräten. Durch das Entfernen redundanter Gewichte oder Neuronen kann die Inferenzgeschwindigkeit erhöht werden, ohne die Modellgenauigkeit wesentlich zu beeinträchtigen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strukturiertes Pruning (engl. structured pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt wird strukturiertes Pruning angewendet, um die Größe des Modells zu reduzieren, indem ganze Schichten oder Filter entfernt werden, anstatt nur einzelne Gewichte zu prunen. Dabei verwenden wir ein Framework für strukturiertes Pruning und integrieren es in unseren Workflow mit dem MNIST-Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das zuvor trainierte Baseline Modell wird geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(os.path.join('assets', 'models', 'tf', 'mnist_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das [Automatic-Structured-Pruning Repository von GitHub](https://github.com/Hahn-Schickard/Automatic-Structured-Pruning) wird heruntergeladen. Anschließend wird das `src` Verzeichnis zum Python-Pfad hinzugefügt und das `pruning` Modul importiert, zur direkten Nutzung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Automatic-Structured-Pruning'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Hahn-Schickard/Automatic-Structured-Pruning\n",
    "sys.path.append(\"Automatic-Structured-Pruning/src\")\n",
    "\n",
    "import pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das Framework für strukturiertes Pruning verwendet. In diesem Beispiel wird ein Modell mit 50% Gewichts-Pruning in vollvernetzen Schichten und 70% Filter-Pruning in den Faltungsschichten erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with pruning\n",
      "Before pruning:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                12832     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,010\n",
      "Trainable params: 16,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "After pruning:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 5)         50        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 5)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 5)         230       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 5)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 125)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                2016      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,522\n",
      "Trainable params: 2,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model built\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.3068 - accuracy: 0.5332 - val_loss: 0.3767 - val_accuracy: 0.9272\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7626 - accuracy: 0.7289 - val_loss: 0.2345 - val_accuracy: 0.9494\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.7640 - val_loss: 0.1878 - val_accuracy: 0.9576\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5910 - accuracy: 0.7862 - val_loss: 0.1761 - val_accuracy: 0.9586\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5691 - accuracy: 0.7964 - val_loss: 0.1670 - val_accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bc88fc4d90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_prune_rate = 50  # 50% Pruning für Dense-Schichten\n",
    "conv_prune_rate = 70   # 70% Pruning für Filter in Convolutional-Schichten\n",
    "\n",
    "# Erstelle ein Modell mit strukturiertem Pruning\n",
    "pruned_model = pruning.factor_pruning(model, dense_prune_rate, conv_prune_rate, 'L2', num_classes=10)\n",
    "\n",
    "# Kompilieren und Trainieren des geprunten Modells\n",
    "pruned_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "pruned_model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach dem Training des strukturiert geprunten Modells wird die Genauigkeit des Modells auf den Testdaten berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Pruning Test Accuracy: 0.961\n"
     ]
    }
   ],
   "source": [
    "# Evaluieren des verkleinerten Modells\n",
    "_, pruned_model_accuracy = pruned_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Structured Pruning Test Accuracy: {pruned_model_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte Modell (strukturiertes Pruning) wird in die Datei `mnist_struct_pruning_model.h5` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.save(os.path.join('assets', 'models', 'tf', 'mnist_struct_pruning_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend wird das Modell in das TensorFlow Lite Format konvertiert, um die Effizienz auf mobilen und eingebetteten Geräten zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp6w35yw5x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dk100\\AppData\\Local\\Temp\\tmp6w35yw5x\\assets\n"
     ]
    }
   ],
   "source": [
    "# Konvertieren des geprunten Modells in TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "tflite_model_pruned = converter.convert()\n",
    "\n",
    "# Speichern des geprunten Modells im TensorFlow Lite Format\n",
    "with open(os.path.join('assets', 'models', 'tflite', 'mnist_struct_pruning_model.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss wird das TensorFlow Lite Modell geladen und getestet, um sicherzustellen, dass das strukturelle Pruning die gewünschte Effizienz erreicht hat, ohne die Leistung des Modells erheblich zu beeinträchtigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Pruned Model Test Accuracy (TFLite): 0.9612\n"
     ]
    }
   ],
   "source": [
    "# Laden des TensorFlow Lite Modells und Initialisieren des Interpreters\n",
    "interpreter = tf.lite.Interpreter(model_path=os.path.join('assets', 'models', 'tflite', 'mnist_struct_pruning_model.tflite'))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Eingabe- und Ausgabedetails abrufen\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Initialisieren der Anzahl korrekter Vorhersagen\n",
    "correct_predictions = 0\n",
    "\n",
    "# Testen des verkleinerten Modells\n",
    "for i in range(len(X_test)):\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    if np.argmax(output_data) == y_test[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Berechnung und Ausgabe der Genauigkeit des TensorFlow Lite Modells\n",
    "structured_pruned_accuracy = correct_predictions / len(X_test)\n",
    "print(f'Structured Pruned Model Test Accuracy (TFLite): {structured_pruned_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code_test_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
